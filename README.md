# ğŸ§  RL-Path: Reinforcement Learning for Pathway Steering (Drug â†’ Gene â†’ Pathway)

RL-Path is a **small bioinformatics reinforcement learning project** that learns a *sequence of drug interventions* to steer a simulated disease state toward a healthier state.

It uses **public data** to build a drugâ†’geneâ†’pathway graph and turns it into an RL environment:
- **DGIdb** drugâ€“gene interactions (**actions = drugs**)
- **Reactome** gene â†’ pathway mappings (**state = pathway activity vector**)

The goal is to keep the project **one-day doable**, interpretable, and aligned with your drug/network + pathway background.

---

## ğŸ“Œ 1. Research Question

Can an RL agent learn an intervention policy (a sequence of drugs) that:
- reduces activity of â€œdisease-associatedâ€ pathways, and
- does so under a cost/penalty constraint (toxicity / number of steps)?

---

## ğŸ’¡ 2. Proposed Solution

We build a lightweight, data-driven Markov Decision Process (MDP):

- **State**: pathway activity vector `s âˆˆ [0,1]^P`
- **Action**: choose a drug from DGIdb (`N` drugs)
- **Transition**: drug perturbs pathways according to its gene targets mapped to Reactome pathways
- **Reward**: improves closeness to a healthy target state while penalizing costly actions

We train a small **DQN (Deep Q-Network)** agent and compare it to a greedy baseline.

---

## âš™ï¸ 3. Methodology

### Data sources (downloadable)

DGIdb (TSV):
```text
https://www.dgidb.org/data/latest/interactions.tsv
```

Reactome mapping (TSV):
```text
https://download.reactome.org/current/Ensembl2Reactome.txt
```

> Note: DGIdb uses gene symbols; Reactome mapping is Ensembl-based. We map symbols â†’ Ensembl using `mygene` (mygene.info API) and cache results locally.

### Environment design

- We pick the top `N` drugs (by number of unique target genes) and top `P` pathways (by coverage).
- We precompute a **drugâ†’pathway effect matrix** `E âˆˆ R^{NÃ—P}`.
- We define a synthetic â€œdisease stateâ€ by assigning higher starting activity to a subset of pathways (â€œdisease pathwaysâ€).
- A drug action decreases pathway activity proportional to `E[action]` (with optional noise and diminishing returns).

---

## ğŸ” 4. Evaluation Workflow

| Step | Description |
|------|-------------|
| Data download | Fetch DGIdb interactions + Reactome mapping |
| Preprocess | Map gene symbols â†’ Ensembl, join to pathways |
| Build effects | Compute drugâ†’pathway effect matrix |
| Train | DQN learns a policy over `T` steps |
| Evaluate | Compare DQN vs greedy baseline |
| Artifacts | Save metrics + plots + example trajectories |

---

## ğŸ§± 5. Repository Structure

```text
RL-Path/
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â”œâ”€ src/
â”‚  â”œâ”€ preprocess.py
â”‚  â”œâ”€ env.py
â”‚  â”œâ”€ dqn.py
â”‚  â””â”€ baselines.py
â”œâ”€ train.py
â”œâ”€ evaluate.py
â”œâ”€ report.md
â””â”€ artifacts/              
```

---

## ğŸ§© 6. Usage

### Install

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Download + preprocess

### Download data

https://www.dgidb.org/data/latest/interactions.tsv  stored at ./data/raw as dgidb_interactions.tsv
https://reactome.org/download/current/Ensembl2Reactome.txt stored at ./data/raw/ as Ensembl2Reactome.txt

### Train

```bash
python train.py --episodes 400 --steps 10 --top_drugs 60 --top_pathways 40
```

### Evaluate

```bash
python evaluate.py --steps 10 --top_drugs 60 --top_pathways 40
```

Artifacts land in `artifacts/`:
- `learning_curve.png`
- `policy_rollouts.json`
- `metrics.json`

---

## ğŸ§ª 7. Expected Results

You should see:
- increasing episodic return for DQN
- DQN achieves better final â€œhealth distanceâ€ than greedy under the same step budget
- interpretable sequences of drugs (actions) that cover disease pathways

---

## ğŸ‘©â€ğŸ’» Author

Developed by Seirana, generated with assistance from Leo.
